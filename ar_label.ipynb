{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os,errno\n",
    "import sys\n",
    "from scipy.ndimage.measurements import label\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "dir_data='/Users/lexihenny/'\n",
    "dir2='/Volumes/Extreme Pro 1/'\n",
    "dir3='/Volumes/My Passport/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945c7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####WITHOUT SIZE CONDITION TO CHECK FOR ELIMINATION\n",
    "\n",
    "#yrs=np.arange(1940,1941,1)\n",
    "yrs=np.arange(2004,2020,1)\n",
    "num_total=0\n",
    "num_new=0\n",
    "for i in range(len(yrs)):\n",
    "    year=yrs[i]\n",
    "    print(year) \n",
    "    #ds=xr.open_dataset(dir2+'era_5_ar_detection_polar_'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra_2_ar_detection_'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'era_5_ar_detection_test_'+str(year)+'.nc')\n",
    "    \n",
    "    #ds=xr.open_dataset(dir2+'era5.ar.tempestlr'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'era5.ar.reid500.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'era5.ar.mundhenkv3.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra2.ar.lorav2.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra2.ar.cndl.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra2.ar.acv2.'+str(year)+'.nc')\n",
    "    ds=xr.open_dataset(dir2+'jra55.ar.gwv2.'+str(year)+'.nc')\n",
    "    \n",
    "    ds1=xr.open_dataset(dir_data+'jra55gw.ar.labels.model.'+str(year)+'.nc')\n",
    "    \n",
    "    \n",
    "    for j in range(ds.time.size):\n",
    "        ar=ds['ar'][j,:,:]\n",
    " \n",
    "        lons_right=[x for x in ar.lon.values if x>=60.]\n",
    "        lons_left=[x for x in ar.lon.values if x<-60.]\n",
    "        ar_right=ar.sel(lon=lons_right)\n",
    "        ar_left=ar.sel(lon=lons_left)\n",
    "        ar_right['lon']=[x-360. for x in lons_right]\n",
    "        ar_left['lon']=[x+360. for x in lons_left]\n",
    "        ar_full=xr.concat([ar_right,ar,ar_left],dim='lon')\n",
    "\n",
    "        if i==0 and j==0:\n",
    "            lon_array=np.zeros((ar_full.lat.size,ar_full.lon.size))\n",
    "            lat_array=np.zeros((ar_full.lat.size,ar_full.lon.size))\n",
    "            for j1 in range(ar_full.lat.size):\n",
    "                lon_array[j1,:]=ar_full.lon.values\n",
    "            for j1 in range(ar_full.lon.size):\n",
    "                lat_array[:,j1]=ar_full.lat.values\n",
    "\n",
    "        if j%100==0:\n",
    "            print(j)\n",
    "\n",
    "        ar_sel=ar_full.values\n",
    "        structure=np.ones((3,3))\n",
    "        ar_labeled,n=label(ar_sel,structure)\n",
    "        ar_labeled=np.where(ar_sel==1,ar_labeled,np.nan)\n",
    "        \n",
    "        if 1==1:\n",
    "            labeled_final=np.zeros_like(ar_labeled)\n",
    "            elim_list=[]\n",
    "            for k in range(n+1):\n",
    "                ones=np.where(ar_labeled==k,1,0)\n",
    "                num=np.nansum(ones)\n",
    "                if num>0:\n",
    "                    #find corresponding one\n",
    "                    \n",
    "                    lon_check=np.where(ar_labeled==k,lon_array,np.nan)\n",
    "                    lat_check=np.where(ar_labeled==k,lat_array,np.nan)\n",
    "                    lon_check_min=np.nanmin(lon_check)\n",
    "                    lon_check_max=np.nanmax(lon_check)\n",
    "\n",
    "                    lons=lon_check.flatten().tolist()\n",
    "                    lats=lat_check.flatten().tolist()\n",
    "                    lons=[x for x in lons if x>=-1e3]\n",
    "                    lats=[x for x in lats if x>=-1e3]\n",
    "\n",
    "                    zipped_latlon=list(zip(lons,lats))\n",
    "                    select_lon_min=[x[0] for x in zipped_latlon if x[0]==lon_check_min][0]\n",
    "                    select_lat_min=[x[1] for x in zipped_latlon if x[0]==lon_check_min][0]\n",
    "                    select_lon_max=[x[0] for x in zipped_latlon if x[0]==lon_check_max][0]\n",
    "                    select_lat_max=[x[1] for x in zipped_latlon if x[0]==lon_check_max][0]\n",
    "\n",
    "                    a=np.unique(lon_check)\n",
    "                    b=len([x for x in a if x>-1000])\n",
    "                    if (lon_check_min<-180. and lon_check_max>=-180. or lon_check_min<180 and lon_check_max>=180) and b<960:\n",
    "                        if k not in elim_list:\n",
    "                            if lon_check_min<-180:\n",
    "                                alternate_value=np.where(lat_array==select_lat_min,ar_labeled,np.nan)\n",
    "                                alternate_value=np.where(lon_array==select_lon_min+360.,alternate_value,np.nan)\n",
    "                                alternate_value=[x for x in np.unique(alternate_value) if x>=0]\n",
    "                                if len(alternate_value)>1:\n",
    "                                    print('ERROR')\n",
    "                                    sys.exit()\n",
    "                                else:\n",
    "                                    alternate_value=alternate_value[0]\n",
    "                                    \n",
    "                            if lon_check_max>=180:\n",
    "                                alternate_value=np.where(lat_array==select_lat_max,ar_labeled,np.nan)\n",
    "                                alternate_value=np.where(lon_array==select_lon_max-360.,alternate_value,np.nan)\n",
    "                                alternate_value=[x for x in np.unique(alternate_value) if x>=0]\n",
    "                                if len(alternate_value)>1:\n",
    "                                    print('ERROR')\n",
    "                                    sys.exit()\n",
    "                                else:\n",
    "                                    alternate_value=alternate_value[0]\n",
    "                                    \n",
    "                            select_component1=np.where(ar_labeled==alternate_value,k,0)\n",
    "                            labeled_final=labeled_final+ones*k+select_component1\n",
    "                            elim_list.append(alternate_value)\n",
    "        \n",
    "                    else:\n",
    "                        if k not in elim_list:\n",
    "                            labeled_final=labeled_final+ones*k\n",
    "\n",
    "            labeled_final1=xr.zeros_like(ar_full)\n",
    "            labeled_final1[:,:]=labeled_final\n",
    "            labeled_final=labeled_final1.where(labeled_final1>0)\n",
    "            lons_center=[x for x in labeled_final.lon.values if -180.<=x<180.]\n",
    "            labeled_final1=labeled_final1.sel(lon=lons_center)\n",
    "\n",
    "        values=np.unique(labeled_final1)\n",
    "        values=[x for x in values if x>0]\n",
    "        num_total=num_total+len(values)\n",
    "        \n",
    "        field_new=ds1['ar_labeled'][j,:,:]\n",
    "        values=np.unique(field_new)\n",
    "        values=[x for x in values if x>0]\n",
    "        num_new=num_new+len(values)\n",
    "        \n",
    "    print((num_total,num_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdec494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#yrs=np.arange(1940,1941,1)\n",
    "yrs=np.arange(2004,2020,1)\n",
    "for i in range(len(yrs)):\n",
    "    year=yrs[i]\n",
    "    print(year) \n",
    "    #ds=xr.open_dataset(dir2+'era_5_ar_detection_polar_'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra_2_ar_detection_'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'era_5_ar_detection_test_'+str(year)+'.nc')\n",
    "    \n",
    "    ds=xr.open_dataset(dir2+'era5.ar.tempestlr'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'era5.ar.reid500.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir1+'era5.ar.mundhenkv3.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra2.ar.lorav2.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra2.ar.cndl.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'merra2.ar.acv2.'+str(year)+'.nc')\n",
    "    #ds=xr.open_dataset(dir2+'jra55.ar.gwv2.'+str(year)+'.nc')\n",
    "    \n",
    "    for j in range(ds.time.size):\n",
    "        ar=ds['ar'][j,:,:]\n",
    " \n",
    "        lons_right=[x for x in ar.lon.values if x>=60.]\n",
    "        lons_left=[x for x in ar.lon.values if x<-60.]\n",
    "        ar_right=ar.sel(lon=lons_right)\n",
    "        ar_left=ar.sel(lon=lons_left)\n",
    "        ar_right['lon']=[x-360. for x in lons_right]\n",
    "        ar_left['lon']=[x+360. for x in lons_left]\n",
    "        ar_full=xr.concat([ar_right,ar,ar_left],dim='lon')\n",
    "\n",
    "        if i==0 and j==0:\n",
    "            lon_array=np.zeros((ar_full.lat.size,ar_full.lon.size))\n",
    "            lat_array=np.zeros((ar_full.lat.size,ar_full.lon.size))\n",
    "            for j1 in range(ar_full.lat.size):\n",
    "                lon_array[j1,:]=ar_full.lon.values\n",
    "            for j1 in range(ar_full.lon.size):\n",
    "                lat_array[:,j1]=ar_full.lat.values\n",
    "\n",
    "        if j%100==0:\n",
    "            print(j)\n",
    "\n",
    "        ar_sel=ar_full.values\n",
    "        structure=np.ones((3,3))\n",
    "        ar_labeled,n=label(ar_sel,structure)\n",
    "        ar_labeled=np.where(ar_sel==1,ar_labeled,np.nan)\n",
    "        \n",
    "        if 1==1:\n",
    "            labeled_final=np.zeros_like(ar_labeled)\n",
    "            elim_list=[]\n",
    "            for k in range(n+1):\n",
    "                ones=np.where(ar_labeled==k,1,0)\n",
    "                num=np.nansum(ones)\n",
    "                if num>=100:\n",
    "                    #find corresponding one\n",
    "                    \n",
    "                    lon_check=np.where(ar_labeled==k,lon_array,np.nan)\n",
    "                    lat_check=np.where(ar_labeled==k,lat_array,np.nan)\n",
    "                    lon_check_min=np.nanmin(lon_check)\n",
    "                    lon_check_max=np.nanmax(lon_check)\n",
    "\n",
    "                    lons=lon_check.flatten().tolist()\n",
    "                    lats=lat_check.flatten().tolist()\n",
    "                    lons=[x for x in lons if x>=-1e3]\n",
    "                    lats=[x for x in lats if x>=-1e3]\n",
    "\n",
    "                    zipped_latlon=list(zip(lons,lats))\n",
    "                    select_lon_min=[x[0] for x in zipped_latlon if x[0]==lon_check_min][0]\n",
    "                    select_lat_min=[x[1] for x in zipped_latlon if x[0]==lon_check_min][0]\n",
    "                    select_lon_max=[x[0] for x in zipped_latlon if x[0]==lon_check_max][0]\n",
    "                    select_lat_max=[x[1] for x in zipped_latlon if x[0]==lon_check_max][0]\n",
    "\n",
    "                    a=np.unique(lon_check)\n",
    "                    b=len([x for x in a if x>-1000])\n",
    "                    if (lon_check_min<-180. and lon_check_max>=-180. or lon_check_min<180 and lon_check_max>=180) and b<960:\n",
    "                        if k not in elim_list:\n",
    "                            if lon_check_min<-180:\n",
    "                                alternate_value=np.where(lat_array==select_lat_min,ar_labeled,np.nan)\n",
    "                                alternate_value=np.where(lon_array==select_lon_min+360.,alternate_value,np.nan)\n",
    "                                alternate_value=[x for x in np.unique(alternate_value) if x>=0]\n",
    "                                if len(alternate_value)>1:\n",
    "                                    print('ERROR')\n",
    "                                    sys.exit()\n",
    "                                else:\n",
    "                                    alternate_value=alternate_value[0]\n",
    "                                    \n",
    "                            if lon_check_max>=180:\n",
    "                                alternate_value=np.where(lat_array==select_lat_max,ar_labeled,np.nan)\n",
    "                                alternate_value=np.where(lon_array==select_lon_max-360.,alternate_value,np.nan)\n",
    "                                alternate_value=[x for x in np.unique(alternate_value) if x>=0]\n",
    "                                if len(alternate_value)>1:\n",
    "                                    print('ERROR')\n",
    "                                    sys.exit()\n",
    "                                else:\n",
    "                                    alternate_value=alternate_value[0]\n",
    "                                    \n",
    "                            select_component1=np.where(ar_labeled==alternate_value,k,0)\n",
    "                            labeled_final=labeled_final+ones*k+select_component1\n",
    "                            elim_list.append(alternate_value)\n",
    "        \n",
    "                    else:\n",
    "                        if k not in elim_list:\n",
    "                            labeled_final=labeled_final+ones*k\n",
    "\n",
    "            labeled_final1=xr.zeros_like(ar_full)\n",
    "            labeled_final1[:,:]=labeled_final\n",
    "            labeled_final=labeled_final1.where(labeled_final1>0)\n",
    "            lons_center=[x for x in labeled_final.lon.values if -180.<=x<180.]\n",
    "            labeled_final1=labeled_final1.sel(lon=lons_center)\n",
    "\n",
    "        if j==0:\n",
    "            labeled_concat=labeled_final1\n",
    "        else:\n",
    "            labeled_concat=xr.concat([labeled_concat,labeled_final1],dim='time')\n",
    "        \n",
    "    dk=xr.Dataset()\n",
    "    dk['ar_labeled']=(('time','lat','lon'),labeled_concat.values)\n",
    "    dk.coords['time']=labeled_concat.time\n",
    "    dk.coords['lat']=labeled_concat.lat\n",
    "    dk.coords['lon']=labeled_concat.lon\n",
    "    try:\n",
    "        os.remove(dir2+'era5tp.ar.labels.model.'+str(year)+'.nc')\n",
    "    except OSError:\n",
    "        pass\n",
    "    dk.to_netcdf(dir2+'era5tp.ar.labels.model.'+str(year)+'.nc',mode='w',format='NETCDF4')\n",
    "    dk.close()\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs=np.arange(2023,2024,1)\n",
    "for i in range(len(yrs)):\n",
    "    year=yrs[i]\n",
    "    print(year)\n",
    "    ds=xr.open_dataset(dir+'merra_2_ar_detection_labeled_'+str(year)+'.nc')\n",
    "    print(ds)\n",
    "    labeled=ds['ar_labeled']\n",
    "    ar_der=labeled/labeled\n",
    "    ar_der=ar_der.fillna(0)\n",
    "    \n",
    "    dk=xr.Dataset()\n",
    "    dk['ar']=(('time','lat','lon'),ar_der.values)\n",
    "    dk.coords['time']=ar_der.time\n",
    "    dk.coords['lat']=ar_der.lat\n",
    "    dk.coords['lon']=ar_der.lon\n",
    "    \n",
    "    try:\n",
    "        os.remove(dir+'merra_2_ar_detection_'+str(year)+'.nc')\n",
    "    except OSError:\n",
    "        pass\n",
    "    dk.to_netcdf(dir+'merra_2_ar_detection_'+str(year)+'.nc',mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bd04d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
